# Dockerized Sentiment Analysis application

This repo is for developing a Dockerized sentiment analysis application that I built in [this repo](https://github.com/bhavenp/deployable_sentiment_analysis/).

## Steps
1. Build a Docker container that serves the sentiment analysis model. This model should only have to be loaded once when the containers starts up.
2. Build a Docker container that serves the UI through which users can submit a sentence. The UI will then send a request to the model container and show the related sentiment score.

## Present
1. Use the the `sentiment_analysis_env.yaml` file at the root of the repo to create a Conda environment and start it.
	1. Run `conda env create -f sentiment_analysis_env.yaml`.
	2. Run `conda activate sentiment_analysis_env` to start the Conda environment.
2. Install the project by running `pip install -e .`. This will allow all of the modules to be imported correctly.
3. Test that app can be run properly using `pytest`.
	1. Run `pytest -v` from the root of the directory. This will test the application using the tests contained in the `tests/` directory.
	2. At the bottom of your Terminal screen, you should see `8 passed, 5 warnings`, indicating that the app should work correctly.
	3. The warning are generated by Tensorflow because a `tostring()` method is deprecated, which is not really an issue.
4. Start up the application locally:
	1. From the root directory, execute `chmod +x run.sh`. This shell script will start up a Gunicorn server that runs the Flask application.
	2. From the root directory, execute `./run.sh`.
	1. The app will start up on [http://0.0.0.0:8000/](http://0.0.0.0:8000/), which is the home page. A user can input a sentence in the provided text box and click _Submit_ to get a sentiment score for the given sentence.
	2. The app also accomodates HTTP POST requests, which can be sent to [http://0.0.0.0:8000/predict/](http://0.0.0.0:8000//predict/) to get sentiment scores for multiple sentences.
		1. The body of the POST request should look like:
		```
		{
			"sentences":[
						  "this place is the worst!",
            			  "this place is the best!",
            			  "I love this place."
            			]
        }
		```
		2. This can be done using an application such as [Postman](https://www.postman.com/).

## Issues:
1. Pre-trainined model for embedding layer is cached locally, so when the cache is emptied automatically, tensorflow still thinks the model is cached locally.
	1. __Solution:__ I removed the directory where tensorflow_hub caches the model, then I reran the training process. Tested that the app works too.
